# Real-Time Indian Concall Transcription & Insight Streaming

## ğŸ¯ Assignment Overview

Build a prototype system that processes **Indian earnings / conference calls (concalls)** and generates **live insights while the call is happening**.

**Role:** Voice AI Engineer  
**Time Limit:** 3 Days  
**Expected Effort:** 6â€“8 hours  

---

## ğŸ“‹ Problem Statement

Your system should simulate or demonstrate:
- Streaming audio transcription
- Real-time insight detection  
- Live streaming of outputs

---

## ğŸ—ï¸ What You Need to Build

### 1. Streaming Transcription (Audio â†’ Text)
- Use a short audio clip of an Indian concall (real or simulated)
- Process audio in chunks or near-real-time
- Convert speech to text using:
  - Open-source ASR (e.g., Whisper), or
  - Any speech API (free tier or mocked)

### 2. Real-Time Insight Detection
As transcript chunks arrive, generate:
- Rolling summaries
- Key financial signals (revenue, guidance, risks, outlook, etc.)
- Any insights relevant for equity research

### 3. Streaming Output
Stream results using:
- Console output, or
- Backend endpoint (SSE, WebSockets, async generators)

---

## ğŸ“ Project Structure

```
voice_ai_assignment/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ transcription/          # Audio â†’ Text pipeline
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ transcriber.py      # Implement streaming transcription
â”‚   â”œâ”€â”€ insights/               # Real-time insight detection
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ detector.py         # Implement insight extraction
â”‚   â”œâ”€â”€ streaming/              # Output streaming mechanisms
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ streamer.py         # Implement streaming output
â”‚   â””â”€â”€ utils/                  # Shared utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ audio_utils.py      # Audio processing helpers
â”œâ”€â”€ data/
â”‚   â””â”€â”€ samples/                # Place sample audio files here
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ main.py                     # Main entry point
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started

### Prerequisites
- Python 3.9+
- pip or conda

### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd voice_ai_assignment
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Set up environment variables:
```bash
cp .env.example .env
# Edit .env with your API keys if needed
```

### Running the Application

```bash
python main.py --audio data/samples/your_audio.wav
```

---

## âœ… Technical Constraints

- **Primary language:** Python (scripts only)
- No Jupyter or notebook-based solutions
- Code must run in a local IDE
- Use clean, modular code

---

## ğŸ“ Your README Should Explain

When you complete the assignment, update this README to include:

- [ ] What you built
- [ ] High-level architecture
- [ ] How streaming is handled
- [ ] Assumptions and tradeoffs
- [ ] What you would improve with more time

**Optional:** Logs or screenshots demonstrating streaming output

---

## ğŸ Bonus (Optional)

- Speaker diarization (Management vs Analyst)
- Detection of new or changing information
- Sentiment shifts during the call
- Handling Indian accents or Hinglish
- Hindi-to-English translation

---

## ğŸ“Š Evaluation Criteria

We'll evaluate:
- Understanding of real-time systems
- Handling of messy, domain-specific audio
- Quality and usefulness of extracted insights
- Code structure, readability, and fundamentals
- Ownership and clarity of reasoning

**What we DON'T expect:**
- Perfect transcription accuracy
- Fully live market or audio integrations
- Production-grade infrastructure

---

## ğŸ“¬ Submission Instructions

1. Complete your implementation
2. Update this README with your documentation
3. Ensure your repository is public
4. Email your submission to: team@investkode.ai
   - **Subject:** `Assignment Submission â€“ Voice AI Engineer â€“ [Your Name]`
   - Include: Link to your GitHub repository

---

## ğŸ“š Resources

- [OpenAI Whisper](https://github.com/openai/whisper)
- [Faster Whisper](https://github.com/guillaumekln/faster-whisper)
- [Python SSE](https://pypi.org/project/sse-starlette/)
- [WebSockets in Python](https://websockets.readthedocs.io/)

---

Good luck! ğŸš€
